{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04c3659-fbb6-42c2-88df-32d734c3440e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3679f894-81bb-4e20-8239-b7b50e3fe7e5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "import torch\n",
    "import os\n",
    "import pickle\n",
    "import logging\n",
    "import random\n",
    "\n",
    "from tqdm import tqdm\n",
    "from rank_bm25 import BM25Okapi\n",
    "import numpy as np\n",
    "from transformers import pipeline, AutoTokenizer, AutoModel\n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "# Function to load data from a JSON file\n",
    "def load_data(file_name):\n",
    "    with open(file_name, 'r') as json_file:\n",
    "        return json.load(json_file)\n",
    "\n",
    "def create_user_product_matrix(data):\n",
    "    user_ids = set()\n",
    "    product_ids = set()\n",
    "    matrix = {}\n",
    "    doc_id = 0\n",
    "\n",
    "    for user in data:\n",
    "        user_id = user['id']\n",
    "        for review in user['profile']:\n",
    "            product_id = review['productAsin']\n",
    "            user_ids.add(user_id)\n",
    "            product_ids.add(product_id)\n",
    "\n",
    "            # Set default values to \"None\" if text or title is missing or empty\n",
    "            review_title = review.get('title', 'None') or 'None'\n",
    "            review_text = review.get('text', 'None') or 'None'\n",
    "            review_rating = review.get('rating', 'None')\n",
    "            if isinstance(review_rating, float):\n",
    "                review_rating = int(review_rating)\n",
    "\n",
    "            matrix[(user_id, product_id)] = {\n",
    "                \"reviewTitle\": review_title,\n",
    "                \"reviewText\": review_text,\n",
    "                \"doc_id\": doc_id,\n",
    "                \"reviewRating\": review_rating\n",
    "            }\n",
    "            doc_id += 1  # Increment doc_id for the next review\n",
    "\n",
    "    user_index = {user_id: idx for idx, user_id in enumerate(user_ids)}\n",
    "    product_index = {product_id: idx for idx, product_id in enumerate(product_ids)}\n",
    "\n",
    "    return matrix, user_index, product_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c1f8f5e-2e9e-4ca0-9c91-49e7066e72b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_corpus_from_matrix(user_product_matrix):\n",
    "    corpus = []\n",
    "    for (user_id, product_id), review_data in user_product_matrix.items():\n",
    "        review_text = review_data['reviewText'].strip()\n",
    "        review_title = review_data['reviewTitle'].strip()\n",
    "        review_rating = review_data['reviewRating']\n",
    "        doc_id = review_data['doc_id']\n",
    "        \n",
    "        # Include review if either text or title is not empty\n",
    "        if review_text or review_title:\n",
    "            combined_text = f\"{review_title} {review_text}\".strip()\n",
    "            corpus.append({\n",
    "                \"doc_id\": doc_id,\n",
    "                \"user_id\": user_id,\n",
    "                \"product_id\": product_id,\n",
    "                \"reviewText\": review_text,\n",
    "                \"reviewTitle\": review_title,\n",
    "                \"reviewRating\": review_rating,\n",
    "                \"combined\": combined_text  # Combined for ranking purposes\n",
    "            })\n",
    "    \n",
    "    return corpus\n",
    "    \n",
    "def load_or_create(\n",
    "    file_path, \n",
    "    compute_func, \n",
    "    load_func=pickle.load, \n",
    "    save_func=pickle.dump, \n",
    "    overwrite=False, \n",
    "    compute_args=(), \n",
    "    compute_kwargs={}\n",
    "):\n",
    "    \"\"\"\n",
    "    Loads an object from a file if it exists; otherwise, computes it using the provided function,\n",
    "    saves it to the file, and returns it.\n",
    "    \n",
    "    Parameters:\n",
    "        file_path (str): Path to the file where the object is saved/loaded.\n",
    "        compute_func (callable): Function to compute/build the object if not loaded.\n",
    "        load_func (callable, optional): Function to load the object from file. Defaults to pickle.load.\n",
    "        save_func (callable, optional): Function to save the object to file. Defaults to pickle.dump.\n",
    "        overwrite (bool, optional): Whether to overwrite the existing file. Defaults to False.\n",
    "        compute_args (tuple, optional): Positional arguments to pass to compute_func.\n",
    "        compute_kwargs (dict, optional): Keyword arguments to pass to compute_func.\n",
    "        \n",
    "    Returns:\n",
    "        Any: The loaded or computed object.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if os.path.exists(file_path) and not overwrite:\n",
    "            logging.info(f\"Loading object from {file_path}...\")\n",
    "            with open(file_path, 'rb') as f:\n",
    "                obj = load_func(f)\n",
    "            logging.info(f\"Loaded object from {file_path}\")\n",
    "        else:\n",
    "            if os.path.exists(file_path) and overwrite:\n",
    "                logging.info(f\"Overwriting existing file at {file_path}...\")\n",
    "            else:\n",
    "                logging.info(f\"No file found at {file_path}. Computing object...\")\n",
    "            \n",
    "            obj = compute_func(*compute_args, **compute_kwargs)\n",
    "            \n",
    "            with open(file_path, 'wb') as f:\n",
    "                save_func(obj, f)\n",
    "            logging.info(f\"Saved object to {file_path}\")\n",
    "        \n",
    "        return obj\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error in load_or_create for {file_path}: {e}\")\n",
    "        raise\n",
    "        \n",
    "def compute_corpus_embeddings(corpus, contriever_model, tokenizer, batch_size=32):\n",
    "    corpus_embeddings = {}\n",
    "    contriever_model.to(device)  # Move the model to the correct device\n",
    "\n",
    "    for i in tqdm(range(0, len(corpus), batch_size), desc=\"Computing Embeddings\"):\n",
    "        batch = corpus[i:i+batch_size]\n",
    "        texts = [doc['combined'] for doc in batch]\n",
    "        doc_ids = [doc['doc_id'] for doc in batch]\n",
    "\n",
    "        # Tokenize the batch\n",
    "        encoded_input = tokenizer(texts, return_tensors=\"pt\", truncation=True, padding=True, max_length=512).to(device)\n",
    "\n",
    "        try:\n",
    "            with torch.no_grad():\n",
    "                embeddings = contriever_model(**encoded_input).pooler_output  # Shape: (batch_size, hidden_size)\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error during embedding computation: {e}\")\n",
    "            continue\n",
    "\n",
    "        embeddings = embeddings.cpu().numpy()\n",
    "\n",
    "        for doc_id, emb in zip(doc_ids, embeddings):\n",
    "            corpus_embeddings[doc_id] = emb\n",
    "\n",
    "    return corpus_embeddings\n",
    "\n",
    "\n",
    "def process_embedding(emb, device=\"cpu\"):\n",
    "    if isinstance(emb, np.ndarray):\n",
    "        emb = torch.tensor(emb)\n",
    "    if emb.ndim > 1:\n",
    "        emb = emb.squeeze(0)\n",
    "    return emb.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1001809d-05f3-47a9-9cb3-4c9dd586a497",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pgraph_rag_neighbors_ratings_only(\n",
    "    user_id, \n",
    "    product_id, \n",
    "    user_product_matrix, \n",
    "    user_index, \n",
    "    product_index, \n",
    "    query, \n",
    "    corpus_embeddings,  # Precomputed embeddings\n",
    "    corpus,             # Corpus should match embeddings by doc_id\n",
    "    limit=None, \n",
    "    retrieval_method=\"con\", \n",
    "    filter_field=\"reviewTitle\"\n",
    "):\n",
    "    # Retrieve the product index\n",
    "    product_idx = product_index.get(product_id)\n",
    "    if product_idx is None:\n",
    "        print(f\"Product {product_id} not found in product_index.\")\n",
    "        return []\n",
    "    \n",
    "    # Get the user IDs who reviewed the product\n",
    "    user_ids = [uid for (uid, pid) in user_product_matrix.keys() if pid == product_id]\n",
    "    \n",
    "    # Get the corresponding user IDs and their review details for the product\n",
    "    neighbor_ratings = [\n",
    "        {\n",
    "            \"user_id\": uid,\n",
    "            \"reviewRating\": user_product_matrix[(uid, product_id)]['reviewRating'],\n",
    "            \"reviewTitle\": user_product_matrix[(uid, product_id)]['reviewTitle'], \n",
    "            \"reviewText\": user_product_matrix[(uid, product_id)]['reviewText'],\n",
    "            \"doc_id\": user_product_matrix[(uid, product_id)]['doc_id']\n",
    "        }\n",
    "        for uid in user_ids\n",
    "    ]\n",
    "    \n",
    "    # Filter out the current user's own review by excluding any reviews from the user_id\n",
    "    filtered_ratings = [\n",
    "        review for review in neighbor_ratings\n",
    "        if review['user_id'] != user_id\n",
    "    ]\n",
    "    \n",
    "    if not filtered_ratings:\n",
    "        print(\"No neighbor ratings after filtering.\")\n",
    "        return []\n",
    "    \n",
    "    # If only one document is left, return it\n",
    "    if len(filtered_ratings) == 1:\n",
    "        return filtered_ratings\n",
    "    \n",
    "    if retrieval_method == \"con\":\n",
    "        if corpus_embeddings is None:\n",
    "            raise ValueError(\"Corpus embeddings must be provided for Contriever retrieval.\")\n",
    "        \n",
    "        # Retrieve embeddings using doc_id\n",
    "        filtered_embeddings = []\n",
    "        for review in filtered_ratings:\n",
    "            doc_id = review['doc_id']\n",
    "            emb = corpus_embeddings[doc_id]\n",
    "            emb = process_embedding(emb)\n",
    "            filtered_embeddings.append(emb)\n",
    "        \n",
    "        if not filtered_embeddings:\n",
    "            print(\"No valid embeddings for filtered documents.\")\n",
    "            return []\n",
    "        \n",
    "        # Encode the query to get the query embedding\n",
    "        query_embedding = encode_for_contriever(query)\n",
    "        \n",
    "        # Perform Contriever retrieval using the precomputed embeddings\n",
    "        top_k_indices = contriever(query_embedding, filtered_embeddings, k=limit if limit else len(filtered_embeddings))\n",
    "        \n",
    "        # Map back the indices to the filtered ratings\n",
    "        top_k_neighbors = [filtered_ratings[i] for i in top_k_indices]\n",
    "    \n",
    "    else:\n",
    "        # Combine title and text for each review for tokenization/embedding purposes\n",
    "        combined_documents = [\n",
    "            f\"{review['reviewTitle']} {review['reviewText']}\" for review in filtered_ratings\n",
    "        ]\n",
    "        # Use BM25 for tokenized retrieval\n",
    "        top_k_documents = bm25_retriever(query, combined_documents, k=limit if limit else len(combined_documents))\n",
    "        # Map documents back to filtered_ratings\n",
    "        top_k_neighbors = []\n",
    "        for doc in top_k_documents:\n",
    "            index = combined_documents.index(doc)\n",
    "            top_k_neighbors.append(filtered_ratings[index])\n",
    "    \n",
    "    return top_k_neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4247bf72-4a15-4cd7-9620-9821364fa231",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_all_ratings(\n",
    "    user_id, \n",
    "    product_id,  # Add product_id parameter\n",
    "    user_product_matrix, \n",
    "    query, \n",
    "    corpus_embeddings,  # Precomputed embeddings\n",
    "    corpus,             # Corpus should match embeddings by index\n",
    "    limit=None, \n",
    "    retrieval_method=\"con\", \n",
    "    filter_field=\"reviewTitle\"\n",
    "):\n",
    "    # Retrieve all reviews by the user\n",
    "    user_ratings = [\n",
    "        {\n",
    "            \"product_id\": pid,\n",
    "            \"reviewRating\": user_product_matrix[(uid, pid)].get('reviewRating', \"None\"),\n",
    "            \"reviewTitle\": user_product_matrix[(user_id, pid)].get('reviewTitle', \"None\"),\n",
    "            \"reviewText\": user_product_matrix[(user_id, pid)].get('reviewText', \"None\"),\n",
    "            \"doc_id\": user_product_matrix[(user_id, pid)]['doc_id']\n",
    "        }\n",
    "        for (uid, pid) in user_product_matrix.keys() if uid == user_id\n",
    "    ]\n",
    "\n",
    "    if not user_ratings:\n",
    "        print(f\"No reviews found for user {user_id}.\")\n",
    "        return []\n",
    "\n",
    "    # Identify the doc_id of the query item based on product_id\n",
    "    query_doc_id = None\n",
    "    for review in user_ratings:\n",
    "        if review['product_id'] == product_id:\n",
    "            query_doc_id = review['doc_id']\n",
    "            break  # Assuming the user has only one review per product\n",
    "\n",
    "    if query_doc_id is None:\n",
    "        #print(f\"No matching review found for user {user_id} and product {product_id}.\")\n",
    "        # Optionally, proceed without excluding the query item\n",
    "        filtered_ratings = user_ratings\n",
    "    else:\n",
    "        # Filter out the query item using doc_id\n",
    "        filtered_ratings = [\n",
    "            review for review in user_ratings\n",
    "            if review['doc_id'] != query_doc_id\n",
    "        ]\n",
    "\n",
    "    if not filtered_ratings:\n",
    "        #print(\"No other reviews found for the user after filtering.\")\n",
    "        return []\n",
    "\n",
    "    # Combine the title and text for tokenization/embedding\n",
    "    combined_documents = [\n",
    "        f\"{review['reviewTitle']} {review['reviewText']}\" for review in filtered_ratings\n",
    "    ]\n",
    "\n",
    "    if retrieval_method == \"con\":\n",
    "        if corpus_embeddings is None:\n",
    "            raise ValueError(\"Corpus embeddings must be provided for Contriever retrieval.\")\n",
    "\n",
    "        # Retrieve embeddings using doc_id\n",
    "        filtered_embeddings = []\n",
    "        for review in filtered_ratings:\n",
    "            doc_id = review['doc_id']\n",
    "            emb = corpus_embeddings[doc_id]\n",
    "            emb = process_embedding(emb)\n",
    "            filtered_embeddings.append(emb)\n",
    "\n",
    "        if not filtered_embeddings:\n",
    "            print(\"No valid embeddings for filtered documents.\")\n",
    "            return []\n",
    "\n",
    "        # Encode the query to get the query embedding\n",
    "        query_embedding = encode_for_contriever(query)\n",
    "\n",
    "        # Perform Contriever-based retrieval using precomputed embeddings\n",
    "        top_k_indices = contriever(query_embedding, filtered_embeddings, k=limit if limit else len(filtered_embeddings))\n",
    "        \n",
    "        # Map back the indices to the filtered ratings\n",
    "        top_k_user_reviews = [filtered_ratings[i] for i in top_k_indices]\n",
    "    else:\n",
    "        # Use BM25 for tokenized retrieval\n",
    "        top_k_documents = bm25_retriever(query, combined_documents, k=limit if limit else len(combined_documents))\n",
    "        # Map documents back to filtered_ratings\n",
    "        top_k_user_reviews = []\n",
    "        for doc in top_k_documents:\n",
    "            index = combined_documents.index(doc)\n",
    "            top_k_user_reviews.append(filtered_ratings[index])\n",
    "\n",
    "    return top_k_user_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "341b7217-59f2-4067-b682-13dfbaddf346",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def mean_pooling(token_embeddings, mask):\n",
    "    # Mask out padded tokens and calculate mean for non-padded tokens\n",
    "    token_embeddings = token_embeddings.masked_fill(~mask[..., None].bool(), 0.)\n",
    "    sentence_embeddings = token_embeddings.sum(dim=1) / mask.sum(dim=1)[..., None]\n",
    "    return sentence_embeddings\n",
    "\n",
    "def encode_for_contriever(text):\n",
    "    inputs = contriever_tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        contriever_model.to(device)  # Ensure model is on the correct device\n",
    "        outputs = contriever_model(**inputs)\n",
    "        \n",
    "        # Apply mean pooling on the token embeddings with attention mask\n",
    "        embeddings = mean_pooling(outputs.last_hidden_state, inputs['attention_mask'])\n",
    "    \n",
    "    return embeddings.squeeze(0).to(device)  # Ensure shape is [D]\n",
    "\n",
    "\n",
    "def contriever(query_embedding, document_embeddings, k=1):\n",
    "    # Ensure query_embedding is a tensor on the correct device\n",
    "    if not isinstance(query_embedding, torch.Tensor):\n",
    "        raise ValueError(f\"Expected query_embedding to be a tensor, but got {type(query_embedding)}\")\n",
    "    query_embedding = query_embedding.to(device)\n",
    "    \n",
    "    # Ensure document_embeddings are tensors on the correct device\n",
    "    document_embeddings = [emb.to(device) if isinstance(emb, torch.Tensor) else torch.tensor(emb).to(device) for emb in document_embeddings]\n",
    "\n",
    "    # Stack embeddings into tensor of shape [N, D]\n",
    "    document_embeddings = torch.stack(document_embeddings)\n",
    "    \n",
    "    # Calculate cosine similarities between query and document embeddings\n",
    "    similarities = torch.nn.functional.cosine_similarity(document_embeddings, query_embedding.unsqueeze(0), dim=1)\n",
    "    similarities = similarities.cpu().numpy()\n",
    "    \n",
    "    # Ensure similarities is a 1D array\n",
    "    similarities = similarities.squeeze()\n",
    "\n",
    "    # Handle potential NaN values in similarities\n",
    "    if np.isnan(similarities).any():\n",
    "        print(\"Similarities contain NaN values. Replacing NaNs with zeros.\")\n",
    "        similarities = np.nan_to_num(similarities)\n",
    "\n",
    "    # Get the indices of documents sorted by similarity\n",
    "    top_k_indices = np.argsort(similarities)[::-1][:k]\n",
    "    top_k_indices = [int(i) for i in top_k_indices]\n",
    "    \n",
    "    return top_k_indices  # Return the indices of the top-k most similar documents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc4b53c-9a04-4722-a9b7-e0a6ffb9c672",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "def build_bm25_model(corpus, tokenize_func):\n",
    "    combined_documents = [doc[\"combined\"] for doc in corpus]\n",
    "    tokenized_corpus = [tokenize_func(doc) for doc in combined_documents]\n",
    "    bm25_model = BM25Okapi(tokenized_corpus)\n",
    "    return bm25_model\n",
    "\n",
    "def tokenize_for_bm25(text):\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    return tokens\n",
    "\n",
    "def bm25_retriever(query, documents, k=1):\n",
    "    if not documents:\n",
    "        print(\"No valid documents to retrieve.\")\n",
    "        return []  # Return an empty list if all documents were filtered out\n",
    "\n",
    "    # Tokenize the filtered documents and the query using the same tokenizer\n",
    "    tokenized_documents = [tokenize_for_bm25(doc) for doc in documents]\n",
    "    #print(f\"First tokenized document: {tokenized_documents[0] if tokenized_documents else 'No documents'}\")\n",
    "    \n",
    "    # Further filter out any tokenized documents that are empty\n",
    "    tokenized_documents = [tokens for tokens in tokenized_documents if tokens]\n",
    "    \n",
    "    # Check if tokenization resulted in empty documents\n",
    "    if not tokenized_documents:\n",
    "        print(\"Tokenization resulted in no valid tokens.\")\n",
    "        return []  # Return an empty list if tokenization fails\n",
    "    \n",
    "    bm25 = BM25Okapi(tokenized_documents)\n",
    "    tokenized_query = tokenize_for_bm25(query)\n",
    "    #print(f\"Tokenized query: {tokenized_query}\")\n",
    "    doc_scores = bm25.get_scores(tokenized_query)\n",
    "    #print(f\"Document scores: {doc_scores}\")\n",
    "    top_k_indices = np.argsort(doc_scores)[::-1][:k]\n",
    "\n",
    "    return [documents[i] for i in top_k_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd8daab-97c6-48af-834c-db24969706da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_item(\n",
    "    item, \n",
    "    user_product_matrix, \n",
    "    user_index, \n",
    "    product_index, \n",
    "    tokenizer, \n",
    "    corpus, \n",
    "    corpus_embeddings,\n",
    "    bm25_model,\n",
    "    limit, \n",
    "    retrieval_method=\"con\", \n",
    "    filter_field=\"reviewTitle\"\n",
    "):\n",
    "    example_user_id = item['id']\n",
    "    example_product_id = item['profile'][0]['productAsin']\n",
    "\n",
    "    \n",
    "    field_mapping = {\n",
    "        'reviewTitle': 'text', #swapped the query field so ranking is based of the opposite parameter and not part of fold\n",
    "        'reviewText': 'title',\n",
    "        #'reviewRating': 'combined'  # Special handling\n",
    "    }\n",
    "    query_field = field_mapping.get(filter_field)\n",
    "\n",
    "    if filter_field == 'reviewRating':\n",
    "        # Concatenate title and text to form the query\n",
    "        title = item['profile'][0].get('title', '').strip()\n",
    "        text = item['profile'][0].get('text', '').strip()\n",
    "        query = f\"{title} {text}\".strip()\n",
    "    else:\n",
    "        # Fetch query based on the field_mapping\n",
    "        query = item['profile'][0].get(query_field, '').strip()\n",
    "        \n",
    "    if not query:\n",
    "        print(f\"Warning: No '{filter_field}' found for user {item['id']}. Skipping this item.\")\n",
    "\n",
    "    # Pass product_id to exclude the review for the current product\n",
    "    user_ratings = get_user_all_ratings(\n",
    "        user_id=example_user_id,\n",
    "        product_id=example_product_id,\n",
    "        user_product_matrix=user_product_matrix,\n",
    "        query=query,\n",
    "        corpus_embeddings=corpus_embeddings,\n",
    "        corpus=corpus,\n",
    "        limit=limit,\n",
    "        retrieval_method=retrieval_method,\n",
    "        filter_field=filter_field\n",
    "    )\n",
    "    \n",
    "    neighbor_ratings = pgraph_rag_neighbors_ratings_only(\n",
    "        user_id=example_user_id, \n",
    "        product_id=example_product_id, \n",
    "        user_product_matrix=user_product_matrix, \n",
    "        user_index=user_index, \n",
    "        product_index=product_index, \n",
    "        query=query, \n",
    "        corpus_embeddings=corpus_embeddings, \n",
    "        corpus=corpus,\n",
    "        limit=limit, \n",
    "        retrieval_method=retrieval_method, \n",
    "        filter_field=filter_field\n",
    "    )\n",
    "    \n",
    "    # Select a random user profile from the user_product_matrix (excluding the current user)\n",
    "    random_user_id = random.choice([uid for uid in user_index.keys() if uid != example_user_id])\n",
    "    \n",
    "    # Retrieve all reviews for the randomly selected user\n",
    "    all_random_user_reviews = get_user_all_ratings(\n",
    "        user_id=random_user_id,\n",
    "        product_id=None,  # We want all reviews, not filtering by product\n",
    "        user_product_matrix=user_product_matrix,\n",
    "        query=\"\",\n",
    "        corpus_embeddings=corpus_embeddings,\n",
    "        corpus=corpus,\n",
    "        limit=None,  # Get all reviews, we will pick one randomly\n",
    "        retrieval_method=retrieval_method,\n",
    "        filter_field=filter_field\n",
    "    )\n",
    "    \n",
    "    # Select a random review directly from all retrieved reviews\n",
    "    random_review = random.choice(all_random_user_reviews) if all_random_user_reviews else None\n",
    "    \n",
    "    user_review_text = item['profile'][0].get('text', None)\n",
    "    user_review_title = item['profile'][0].get('title', None)\n",
    "    user_review_rating = item['profile'][0].get('rating', None)\n",
    "    if isinstance(user_review_rating, float):\n",
    "        user_review_rating = int(user_review_rating)\n",
    "    \n",
    "    return {\n",
    "        \"user_id\": example_user_id,\n",
    "        \"product_id\": example_product_id,\n",
    "        \"user_review_text\": user_review_text,\n",
    "        \"user_review_title\": user_review_title, \n",
    "        \"user_review_rating\": user_review_rating,\n",
    "        \"user_ratings\": user_ratings,\n",
    "        \"neighbor_ratings\": neighbor_ratings,\n",
    "        \"random_review\": random_review\n",
    "    }\n",
    "\n",
    "\n",
    "def process_and_save(file_data_list, tokenizer, limit, retrieval_method=\"con\", filter_field=\"reviewTitle\", num_items=None):\n",
    "    for data_info in tqdm(file_data_list, desc=\"Processing datasets\", unit=\"dataset\"):\n",
    "        items = data_info['items']\n",
    "        output_file = data_info['output_file']\n",
    "        user_product_matrix = data_info['user_product_matrix']\n",
    "        user_index = data_info['user_index']\n",
    "        product_index = data_info['product_index']\n",
    "        corpus = data_info['corpus']\n",
    "        corpus_embeddings = data_info.get('corpus_embeddings') \n",
    "        bm25_model = data_info.get('bm25_model')\n",
    "    \n",
    "        print(f\"Processing dataset: {output_file}\")\n",
    "        #print(f\"Corpus embeddings is {'not None' if corpus_embeddings else 'None'}\")\n",
    "    \n",
    "        results = []\n",
    "    \n",
    "        # Determine the items to process\n",
    "        if num_items is not None:\n",
    "            items_to_process = items[:num_items]\n",
    "            print(f\"Processing {len(items_to_process)} items out of {len(items)} total items.\")\n",
    "        else:\n",
    "            items_to_process = items\n",
    "            print(f\"Processing all {len(items)} items.\")\n",
    "    \n",
    "        # Inner loop to process each item in the current dataset\n",
    "        print(f\"\\nProcessing data for {output_file}...\")\n",
    "        for item in tqdm(items_to_process, desc=f\"Processing items in {output_file}\", unit=\"item\", leave=False):\n",
    "            result = process_item(\n",
    "                item=item,\n",
    "                user_product_matrix=user_product_matrix,\n",
    "                user_index=user_index,\n",
    "                product_index=product_index,\n",
    "                tokenizer=tokenizer,\n",
    "                corpus=corpus,\n",
    "                corpus_embeddings=corpus_embeddings,\n",
    "                bm25_model=bm25_model,  \n",
    "                limit=limit,\n",
    "                retrieval_method=retrieval_method,\n",
    "                filter_field=filter_field  # Pass the filter_field to process_item\n",
    "            )\n",
    "            if result is not None:\n",
    "                results.append(result)\n",
    "    \n",
    "        # Save the results to a JSON file\n",
    "        with open(output_file, 'w') as outfile:\n",
    "            json.dump(results, outfile, indent=4)\n",
    "    \n",
    "        print(f\"Ranked ratings saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb21fb2-3f0d-45e9-aa62-6f14dc989a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "limit = 5\n",
    "RETRIEVAL_METHOD = 'con'\n",
    "\n",
    "file_path = \"../data/AmazonReview/\"\n",
    "file_name_base = \"amazon\"\n",
    "\n",
    "ranked_suffix = f\"RANKING\"\n",
    "file_suffixes = [\"test\", \"dev\"]\n",
    "\n",
    "# Construct the full file names with paths using the suffixes\n",
    "file_names = [os.path.join(file_path, f\"{file_name_base}_{suffix}.json\") for suffix in file_suffixes]\n",
    "\n",
    "# Define directories\n",
    "embeddings_dir = os.path.join(file_path, \"embeddings\")\n",
    "bm25_dir = os.path.join(file_path, \"bm25_models\")\n",
    "\n",
    "# Create directories if they don't exist\n",
    "os.makedirs(embeddings_dir, exist_ok=True)\n",
    "os.makedirs(bm25_dir, exist_ok=True)\n",
    "\n",
    "test_embeddings_path = os.path.join(embeddings_dir, \"test_corpus_embeddings.pkl\")\n",
    "dev_embeddings_path = os.path.join(embeddings_dir, \"dev_corpus_embeddings.pkl\")\n",
    "test_bm25_path = os.path.join(bm25_dir, \"test_bm25_model.pkl\")\n",
    "dev_bm25_path = os.path.join(bm25_dir, \"dev_bm25_model.pkl\")\n",
    "\n",
    "# Load the datasets\n",
    "test_users = load_data(file_names[0])\n",
    "dev_users = load_data(file_names[1])\n",
    "\n",
    "test_user_product_matrix, test_user_index, test_product_index = create_user_product_matrix(test_users)\n",
    "dev_user_product_matrix, dev_user_index, dev_product_index = create_user_product_matrix(dev_users)\n",
    "\n",
    "test_corpus = retrieve_corpus_from_matrix(test_user_product_matrix)\n",
    "dev_corpus = retrieve_corpus_from_matrix(dev_user_product_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d80c91-d413-4294-a562-c57c61c5d305",
   "metadata": {},
   "outputs": [],
   "source": [
    "if RETRIEVAL_METHOD == 'con':\n",
    "    # Initialize tokenizer and model\n",
    "    contriever_tokenizer = AutoTokenizer.from_pretrained(\"facebook/contriever\")\n",
    "    contriever_model = AutoModel.from_pretrained(\"facebook/contriever\").to(device)\n",
    "    \n",
    "    # Load or compute embeddings for Test Corpus\n",
    "    test_corpus_embeddings = load_or_create(\n",
    "        file_path=test_embeddings_path,\n",
    "        compute_func=compute_corpus_embeddings,\n",
    "        overwrite=False,\n",
    "        compute_args=(test_corpus, contriever_model, contriever_tokenizer),\n",
    "        compute_kwargs={'batch_size': 32}\n",
    "    )\n",
    "    \n",
    "    # Load or compute embeddings for Dev Corpus\n",
    "    dev_corpus_embeddings = load_or_create(\n",
    "        file_path=dev_embeddings_path,\n",
    "        compute_func=compute_corpus_embeddings,\n",
    "        overwrite=False,\n",
    "        compute_args=(dev_corpus, contriever_model, contriever_tokenizer),\n",
    "        compute_kwargs={'batch_size': 32}\n",
    "    )\n",
    "\n",
    "elif RETRIEVAL_METHOD == 'bm25':\n",
    "    # Load or build BM25 model for Test Corpus\n",
    "    test_bm25_model = load_or_create(\n",
    "        file_path=test_bm25_path,       # file_path\n",
    "        compute_func=build_bm25_model, # compute_func\n",
    "        overwrite=False,                # overwrite\n",
    "        compute_args=(test_corpus, tokenize_for_bm25)  # compute_args as tuple\n",
    "    )\n",
    "    \n",
    "    # Load or build BM25 model for Dev Corpus\n",
    "    dev_bm25_model = load_or_create(\n",
    "        file_path=dev_bm25_path,\n",
    "        compute_func=build_bm25_model,\n",
    "        overwrite=False,\n",
    "        compute_args=(dev_corpus, tokenize_for_bm25)\n",
    "    )\n",
    "else:\n",
    "    raise ValueError(\"Invalid retrieval method specified. Choose 'bm25' or 'con'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2260b71-577f-4ca9-b286-5edc97e1798d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the file_data_list with BM25 or Contriever models and corpora\n",
    "file_data_list = [\n",
    "    {\n",
    "        'items': test_users,\n",
    "        'output_file_template': os.path.join(\n",
    "            file_path,\n",
    "            f\"{ranked_suffix}-{file_name_base}_test_{{filter_field}}_{RETRIEVAL_METHOD}.json\"\n",
    "        ),\n",
    "        'user_product_matrix': test_user_product_matrix,\n",
    "        'user_index': test_user_index,\n",
    "        'product_index': test_product_index,\n",
    "        'corpus': test_corpus,\n",
    "        'corpus_embeddings': test_corpus_embeddings if RETRIEVAL_METHOD == 'con' else None,\n",
    "        'bm25_model': test_bm25_model if RETRIEVAL_METHOD == 'bm25' else None\n",
    "    },\n",
    "    {\n",
    "        'items': dev_users,\n",
    "        'output_file_template': os.path.join(\n",
    "            file_path,\n",
    "            f\"{ranked_suffix}-{file_name_base}_dev_{{filter_field}}_{RETRIEVAL_METHOD}.json\"\n",
    "        ),\n",
    "        'user_product_matrix': dev_user_product_matrix,\n",
    "        'user_index': dev_user_index,\n",
    "        'product_index': dev_product_index,\n",
    "        'corpus': dev_corpus,\n",
    "        'corpus_embeddings': dev_corpus_embeddings if RETRIEVAL_METHOD == 'con' else None,\n",
    "        'bm25_model': dev_bm25_model if RETRIEVAL_METHOD == 'bm25' else None\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db21b730-b6c7-42bc-a0bc-abf6ef822fab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Define the filter_fields you want to process\n",
    "#filter_fields = ['reviewTitle', 'reviewText', 'reviewRating']\n",
    "filter_fields = ['reviewTitle']\n",
    "for filter_field in filter_fields:\n",
    "    print(f\"\\nProcessing with filter_field: {filter_field}\")\n",
    "\n",
    "    # Update the output_file for each dataset\n",
    "    for data_info in file_data_list:\n",
    "        data_info['output_file'] = data_info['output_file_template'].format(filter_field=filter_field)\n",
    "\n",
    "    # Process and save the datasets for this filter_field\n",
    "    process_and_save(\n",
    "        file_data_list,\n",
    "        tokenizer=None,\n",
    "        limit=limit,\n",
    "        retrieval_method=RETRIEVAL_METHOD,\n",
    "        filter_field=filter_field,\n",
    "        #num_items=2,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a4f6b6-2de2-4dd0-a832-64075683f079",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "from ipywidgets import Button\n",
    "\n",
    "def shutdown_kernel():\n",
    "    from IPython.display import display\n",
    "    display(\"Shutting down kernel...\")\n",
    "    get_ipython().kernel.do_shutdown(True)\n",
    "\n",
    "shutdown_kernel()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4968a729-10f1-46d1-bf64-80eff8086b0d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
