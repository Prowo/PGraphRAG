{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04c3659-fbb6-42c2-88df-32d734c3440e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c65d6de7-9626-422c-bd12-1bba9293b50f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from transformers import pipeline, AutoTokenizer \n",
    "import time\n",
    "import torch\n",
    "import json\n",
    "\n",
    "llama3_model = pipeline(\"text-generation\", model=\"meta-llama/Meta-Llama-3.1-8B-Instruct\", device_map=\"auto\",)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Meta-Llama-3.1-8B-Instruct\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1fd8daab-97c6-48af-834c-db24969706da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate a title for each review using the combined file\n",
    "def generate_title_for_reviews(data, max_input_length, max_output_length, tokenizer, k, mode=\"both\", task=None):\n",
    "    results = []\n",
    "\n",
    "    # Start timing\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Process the dataset item by item\n",
    "    for item in tqdm(data, desc=\"Processing Reviews\"):\n",
    "        result = process_item(item, max_input_length, max_output_length, tokenizer, k, mode=mode, task=task)\n",
    "        results.append(result)\n",
    "\n",
    "    # End timing\n",
    "    end_time = time.time()\n",
    "    print(f\"Time taken to generate titles for mode '{mode}': {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "    return results\n",
    "\n",
    "# Function to process a single item (user's review) from the combined JSON file\n",
    "def process_item(item, max_input_length, max_output_length, tokenizer, k, mode=\"both\", task=None):\n",
    "    example_user_id = item['user_id']\n",
    "    example_product_id = item['product_id']\n",
    "\n",
    "    # Adjust the query based on the task type (e.g., title, review, or both)\n",
    "    if task == \"title\":\n",
    "        query = item.get('user_review_title', '')  # Use the review title as the query\n",
    "    elif task == \"review\":\n",
    "        query = item.get('user_review_text', '')  # Use the review text as the query\n",
    "\n",
    "    # Retrieve the pre-ranked data for the user from the combined file\n",
    "    user_ratings = item.get('user_ratings', [])[:k]  \n",
    "    neighbor_ratings = item.get('neighbor_ratings', [])[:k]  \n",
    "    all_ratings = item.get('all_ratings', [])[:k]  \n",
    "\n",
    "    # Construct the prompt using the top-k user and neighbor ratings\n",
    "    prompt = tokenized_prompt(user_ratings, neighbor_ratings, query, max_input_length, tokenizer, mode=mode, task=task)\n",
    "    \n",
    "    # Generate text using the Llama 3 model\n",
    "    generated_text = llama3_model(prompt, max_new_tokens=max_output_length, do_sample=True, return_full_text=False)\n",
    "    \n",
    "    # Extract the generated title\n",
    "    title = generated_text[0]['generated_text'].strip()\n",
    "\n",
    "    return {\"user_id\": item['user_id'], \"product_id\": item['product_id'], \"output\": title}\n",
    "\n",
    "# Tokenized prompt function\n",
    "def tokenized_prompt(user_ratings, neighbor_ratings, inp, max_input_length, tokenizer, mode=\"both\", task=\"title\"):\n",
    "    user_contexts = []\n",
    "    neighbor_contexts = []\n",
    "\n",
    "    # Create user review context if mode is 'both' or 'user'\n",
    "    if mode in [\"both\", \"user\"]:\n",
    "        for idx, review in enumerate(user_ratings, start=1):\n",
    "            context = f\"User's Product {idx} Review: Review text: \\\"{review['reviewText']}\\\", Review title: \\\"{review['reviewTitle']}\\\"\"\n",
    "            tokens = tokenizer(context, max_length=max_input_length, truncation=True)\n",
    "            user_contexts.append(tokenizer.batch_decode([tokens['input_ids']], skip_special_tokens=True)[0])\n",
    "\n",
    "    # Create neighbor review context if mode is 'both' or 'neighbor'\n",
    "    if mode in [\"all\", \"both\", \"neighbor\"]:\n",
    "        for idx, neighbor in enumerate(neighbor_ratings, start=1):\n",
    "            context = f\"User {idx} Product Review: Review text: \\\"{neighbor['reviewText']}\\\", Review title: \\\"{neighbor['reviewTitle']}\\\"\"\n",
    "            tokens = tokenizer(context, max_length=max_input_length, truncation=True)\n",
    "            neighbor_contexts.append(tokenizer.batch_decode([tokens['input_ids']], skip_special_tokens=True)[0])\n",
    "\n",
    "    # Combine contexts based on mode\n",
    "    combined_contexts = []\n",
    "    if mode in [\"both\", \"user\"]:\n",
    "        combined_contexts.append(\"User's Own Reviews:\\n\")\n",
    "        combined_contexts.extend(user_contexts)\n",
    "    if mode in [\"all\", \"both\", \"neighbor\"]:\n",
    "        combined_contexts.append(\"\\nOther Users' Reviews:\\n\")\n",
    "        combined_contexts.extend(neighbor_contexts)\n",
    "\n",
    "    combined_context_str = \"\\n\".join(combined_contexts)\n",
    "    \n",
    "    # Custom prompting words based on mode\n",
    "    if mode == \"both\":\n",
    "        intro = \"Given the following reviews from the same user and other users on the same product:\\n\"\n",
    "    elif mode == \"all\":\n",
    "        intro = \"Given the following reviews from any user on any product:\\n\"\n",
    "    elif mode == \"user\":\n",
    "        intro = \"Given the following reviews from the user on different products:\\n\"\n",
    "    elif mode == \"neighbor\":\n",
    "        intro = \"Given the following reviews from other users on the same product:\\n\"\n",
    "\n",
    "    if task == \"title\": # the \"original\" directions\n",
    "        direction = \"\\nGenerate a title for the following product review from this user without any explanation: Review:\"\n",
    "        gen_direction = \"Generate the answer in 10 words or less using the format: 'The title is:'.\\n\"\n",
    "    elif task == \"review\":\n",
    "        direction = \"\\nGenerate a review for the following product from this user given the review title, without any explanation: Title:\"\n",
    "        gen_direction = \"Generate a review using the format: 'The review text is: '.\\n\"\n",
    "\n",
    "    # Final prompt with specific instruction\n",
    "    combined_prompt = (\n",
    "        f\"<|start_header_id|>user<|end_header_id|>\"\n",
    "        f\"{intro}\"\n",
    "        f\"{combined_context_str}.\\n\"\n",
    "        f\"{direction} \\\"{inp}\\\".\\n\"\n",
    "        f\"{gen_direction}\"\n",
    "        f\"Do NOT generate anything else!.\"\n",
    "        f\"<<|eot_id|><|start_header_id|>assistant<|end_header_id|>\"\n",
    "    )\n",
    "    \n",
    "    return combined_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f92a8059-bf25-48d1-b38d-de00e3869e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define mock data for testing\n",
    "mock_item = {\n",
    "    \"user_id\": \"TEST_USER_123\",\n",
    "    \"product_id\": \"TEST_PRODUCT_456\",\n",
    "    \"user_review_text\": \"This is a great product, highly recommend!\",\n",
    "    \"user_ratings\": [\n",
    "        {\"reviewTitle\": \"Excellent choice\", \"reviewText\": \"Loved the product, great value!\"},\n",
    "        {\"reviewTitle\": \"Worth the money\", \"reviewText\": \"Superb quality, will buy again.\"}\n",
    "    ],\n",
    "    \"neighbor_ratings\": [\n",
    "        {\"reviewTitle\": \"Good buy\", \"reviewText\": \"Very satisfied with the product quality.\"},\n",
    "        {\"reviewTitle\": \"Average product\", \"reviewText\": \"It works, but expected better quality.\"}\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Set parameters\n",
    "max_input_length = 512\n",
    "max_output_length = 218\n",
    "k = 2  # Take the top-2 ratings\n",
    "mode = \"both\"  # Use both user and neighbor reviews\n",
    "task = \"review\"\n",
    "# Test the tokenized prompt\n",
    "prompt = tokenized_prompt(\n",
    "    user_ratings=mock_item['user_ratings'],\n",
    "    neighbor_ratings=mock_item['neighbor_ratings'],\n",
    "    inp=mock_item['user_review_text'],\n",
    "    max_input_length=max_input_length,\n",
    "    tokenizer=tokenizer,\n",
    "    mode=mode,\n",
    "    task=task\n",
    ")\n",
    "\n",
    "# Print the generated prompt to verify it\n",
    "print(\"Generated Prompt:\")\n",
    "print(prompt)\n",
    "\n",
    "# Generate text using the Llama 3 model\n",
    "generated_text = llama3_model(prompt, max_new_tokens=max_output_length, do_sample=True, return_full_text=False)\n",
    "\n",
    "# Extract the generated title\n",
    "title = generated_text[0]['generated_text'].strip()\n",
    "\n",
    "# Print the generated title\n",
    "print(\"Generated Title:\")\n",
    "print(title)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "879b8cef-0422-4d4e-ab08-0b67f1877133",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # if mode in [\"both\", \"user\"]:\n",
    "    #     for idx, review in enumerate(user_ratings, start=1):\n",
    "    #         context = \"User's Product {} Review: Review text: \\\"{}\\\", Review title: \\\"{}\\\"\".format(\n",
    "    #             idx, review[\"reviewText\"], review.get(\"reviewTitle\", \"No title available\"),\n",
    "    #         )\n",
    "    #         tokens = tokenizer(context, max_length=max_input_length, truncation=True)\n",
    "    #         user_contexts.append(tokenizer.batch_decode([tokens['input_ids']], skip_special_tokens=True)[0])\n",
    "\n",
    "    # # Create neighbor review context if mode is 'both', 'neighbor', or 'all'\n",
    "    # if mode in [\"all\", \"both\", \"neighbor\"]:\n",
    "    #     for idx, neighbor in enumerate(neighbor_ratings, start=1):\n",
    "    #         context = \"User {} Product Review: Review text: \\\"{}\\\", Review title: \\\"{}\\\"\".format(\n",
    "    #             idx, neighbor[\"reviewText\"], neighbor.get(\"reviewTitle\", \"No title available\"),\n",
    "    #         )\n",
    "    #         tokens = tokenizer(context, max_length=max_input_length, truncation=True)\n",
    "    #         neighbor_contexts.append(tokenizer.batch_decode([tokens['input_ids']], skip_special_tokens=True)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "302eb03c-c79c-4a28-93c5-6e8591e86c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate titles for multiple modes and k-values\n",
    "def generate_title_for_all_modes(data, max_input_length, max_output_length, tokenizer, k_values=[2, 3, 5]):\n",
    "    modes = [\"all\", \"both\", \"user\", \"neighbor\"]\n",
    "    task=\"review\"\n",
    "    for k in k_values:\n",
    "        for mode in modes:\n",
    "            print(f\"Processing mode: {mode} with k={k}\")\n",
    "            \n",
    "            # Generate titles for the current mode and k value\n",
    "            results = generate_title_for_reviews(\n",
    "                data, \n",
    "                max_input_length, \n",
    "                max_output_length, \n",
    "                tokenizer, \n",
    "                k=k,  # Now passing k for internal handling\n",
    "                mode=mode,\n",
    "                task=task\n",
    "            )\n",
    "            \n",
    "            # Define the output file name\n",
    "            output_file = f'results_test_{mode}_k{k}_review.json'\n",
    "            \n",
    "            # Save the results to a JSON file\n",
    "            with open(output_file, 'w') as f:\n",
    "                json.dump(results, f, indent=4)\n",
    "            \n",
    "            print(f\"Results for mode '{mode}' with k={k} have been saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea482030-d353-4093-9320-e12ee7c9d354",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Function to load data from a JSON file\n",
    "def load_data(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        return json.load(file)\n",
    "\n",
    "ranked_test_file = \"../data/AmazonReview/amazon_title_generation_questions_test_ranked_k_5_reviewText.json\"\n",
    "ranked_data = load_data(ranked_test_file)\n",
    "\n",
    "# Call the function to process the data\n",
    "generate_title_for_all_modes(\n",
    "    data=ranked_data,\n",
    "    max_input_length=512,\n",
    "    max_output_length=256,\n",
    "    tokenizer=tokenizer,\n",
    "    k_values=[1, 2, 4]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d54057-c822-4adb-83e7-5e606005934c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate titles for multiple modes and k-values\n",
    "def generate_title_for_all_modes(data, max_input_length, max_output_length, tokenizer, k_values=[2, 3, 5]):\n",
    "    modes = [\"all\", \"both\", \"user\", \"neighbor\"]\n",
    "    task=\"review\"\n",
    "    for k in k_values:\n",
    "        for mode in modes:\n",
    "            print(f\"Processing mode: {mode} with k={k}\")\n",
    "            \n",
    "            # Generate titles for the current mode and k value\n",
    "            results = generate_title_for_reviews(\n",
    "                data, \n",
    "                max_input_length, \n",
    "                max_output_length, \n",
    "                tokenizer, \n",
    "                k=k,  # Now passing k for internal handling\n",
    "                mode=mode,\n",
    "                task=task\n",
    "            )\n",
    "            \n",
    "            # Define the output file name\n",
    "            output_file = f'results_dev_{mode}_k{k}_review.json'\n",
    "            \n",
    "            # Save the results to a JSON file\n",
    "            with open(output_file, 'w') as f:\n",
    "                json.dump(results, f, indent=4)\n",
    "            \n",
    "            print(f\"Results for mode '{mode}' with k={k} have been saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4323a598-30da-4785-babf-7a0cc14fa8bd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ranked_dev_file = \"../data/AmazonReview/amazon_title_generation_questions_dev_ranked_k_5_reviewText.json\"\n",
    "ranked_data = load_data(ranked_dev_file)\n",
    "\n",
    "# Call the function to process the data\n",
    "generate_title_for_all_modes(\n",
    "    data=ranked_data,\n",
    "    max_input_length=512,\n",
    "    max_output_length=256,\n",
    "    tokenizer=tokenizer,\n",
    "    k_values=[1, 2, 4]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a4f6b6-2de2-4dd0-a832-64075683f079",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "from ipywidgets import Button\n",
    "\n",
    "def shutdown_kernel():\n",
    "    from IPython.display import display\n",
    "    display(\"Shutting down kernel...\")\n",
    "    get_ipython().kernel.do_shutdown(True)\n",
    "\n",
    "shutdown_kernel()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
